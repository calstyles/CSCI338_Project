{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "79f3827f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on local URL:  http://127.0.0.1:7862/\n",
      "\n",
      "To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/plain": "<IPython.lib.display.IFrame at 0x7f8f2d796e10>",
      "text/html": "\n        <iframe\n            width=\"900\"\n            height=\"500\"\n            src=\"http://127.0.0.1:7862/\"\n            frameborder=\"0\"\n            allowfullscreen\n            \n        ></iframe>\n        "
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from __future__ import print_function, division\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.optim import lr_scheduler\n",
    "from torch.autograd import Variable\n",
    "import numpy as np\n",
    "import torchvision\n",
    "from torchvision import datasets, models, transforms\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import os\n",
    "import copy\n",
    "import gradio as gr\n",
    "from PIL import Image\n",
    "\"\"\"This file allows the user to create a sharable UI or run one locally on\n",
    "    their computer. Simply load the trained model of your choice at the bottom\n",
    "    \"\"\"\n",
    "\n",
    "\n",
    "\n",
    "#This function takes in a picture as input, preforms the required transformations\n",
    "#and matches the str() tensor output to an elif block to make a prediction.\n",
    "def predict(inp):\n",
    "\n",
    "    data_transforms = transforms.Compose([\n",
    "           transforms.Resize(256),\n",
    "            transforms.CenterCrop(224),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225))\n",
    "        ])\n",
    "    \n",
    "    inp = data_transforms(inp).unsqueeze(0)\n",
    "    outputs = vgg16(inp)\n",
    "    x, preds = torch.max(outputs.data, 1)\n",
    "    labels = [preds[j] for j in range(inp.size()[0])]\n",
    "    predicted_labels = str(labels)\n",
    "    ans = \"\"\n",
    "        \n",
    "    if(predicted_labels == \"[tensor(1)]\"):\n",
    "        ans = \"Line graph\"\n",
    "    elif(predicted_labels == \"[tensor(2)]\"):\n",
    "        ans = \"Pie graph\"\n",
    "    elif(predicted_labels == \"[tensor(0)]\"):\n",
    "        ans = \"Bar graph\"\n",
    "    else:\n",
    "        ans = \"Unable to identify graph make sure it is either:\" \\\n",
    "              \"Bar, line or pie graph\"\n",
    "    \n",
    "    return ans\n",
    "\n",
    "\n",
    "def main():\n",
    "  pass\n",
    "\n",
    "if __name__ == '__main__':\n",
    "\n",
    "    # # Load the pretrained model from pytorch\n",
    "    vgg16 = models.vgg16_bn()\n",
    "\n",
    "    # Freeze training for all layers\n",
    "    for param in vgg16.features.parameters():\n",
    "        param.require_grad = False\n",
    "\n",
    "    # Newly created modules have require_grad=True by default\n",
    "    num_features = vgg16.classifier[6].in_features\n",
    "    features = list(vgg16.classifier.children())[:-1]  # Remove last layer\n",
    "    features.extend([nn.Linear(num_features, 3)])  # Add our layer with 3 outputs\n",
    "    vgg16.classifier = nn.Sequential(*features)  # Replace the model classifier\n",
    "\n",
    "\n",
    "    #used in transfer learning\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "    #optimization (possibly could use atom)\n",
    "    optimizer_ft = optim.SGD(vgg16.parameters(), lr=0.001, momentum=0.9)\n",
    "    exp_lr_scheduler = lr_scheduler.StepLR(optimizer_ft, step_size=7, gamma=0.1)\n",
    "\n",
    "\n",
    "    #load your trained model here\n",
    "    #If your device is capable of running CUDA go ahead and delete/change the map location to reflect that\n",
    "    vgg16.load_state_dict(torch.load(r\"/Users/matthew/PycharmProjects/CSCI338_Project/VGG16_graphs.pt\",map_location=torch.device('cpu')))\n",
    "\n",
    "\n",
    "    #lock the paramters as to not overtrain\n",
    "    vgg16.eval()\n",
    "\n",
    "\n",
    "    #call the Gradio interface which asks\n",
    "    # fn =  What function do you want me to pass input to?\n",
    "    # inputs = What type of input can I accept?\n",
    "    # outputs = What type of output would you like?\n",
    "    gr.Interface(fn=predict,\n",
    "             inputs=gr.inputs.Image(type=\"pil\"),\n",
    "             outputs=gr.outputs.Label(num_top_classes=3)).launch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a237776",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2b1d3f8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d42bb766",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}