{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a1bbe8ab",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'D:\\\\School\\\\SE\\\\Group_Project\\\\data/train'",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mFileNotFoundError\u001B[0m                         Traceback (most recent call last)",
      "\u001B[0;32m/var/folders/tx/p_26tyls7_lf2l9k5m1xv85w0000gn/T/ipykernel_58814/2083351012.py\u001B[0m in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[1;32m     65\u001B[0m             \u001B[0mtransform\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mdata_transforms\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0mx\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     66\u001B[0m         )\n\u001B[0;32m---> 67\u001B[0;31m         \u001B[0;32mfor\u001B[0m \u001B[0mx\u001B[0m \u001B[0;32min\u001B[0m \u001B[0;34m[\u001B[0m\u001B[0mTRAIN\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mVAL\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mTEST\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m     68\u001B[0m     }\n\u001B[1;32m     69\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/var/folders/tx/p_26tyls7_lf2l9k5m1xv85w0000gn/T/ipykernel_58814/2083351012.py\u001B[0m in \u001B[0;36m<dictcomp>\u001B[0;34m(.0)\u001B[0m\n\u001B[1;32m     65\u001B[0m             \u001B[0mtransform\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mdata_transforms\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0mx\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     66\u001B[0m         )\n\u001B[0;32m---> 67\u001B[0;31m         \u001B[0;32mfor\u001B[0m \u001B[0mx\u001B[0m \u001B[0;32min\u001B[0m \u001B[0;34m[\u001B[0m\u001B[0mTRAIN\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mVAL\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mTEST\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m     68\u001B[0m     }\n\u001B[1;32m     69\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/opt/anaconda3/envs/deeplearning/lib/python3.7/site-packages/torchvision/datasets/folder.py\u001B[0m in \u001B[0;36m__init__\u001B[0;34m(self, root, transform, target_transform, loader, is_valid_file)\u001B[0m\n\u001B[1;32m    227\u001B[0m                                           \u001B[0mtransform\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mtransform\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    228\u001B[0m                                           \u001B[0mtarget_transform\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mtarget_transform\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 229\u001B[0;31m                                           is_valid_file=is_valid_file)\n\u001B[0m\u001B[1;32m    230\u001B[0m         \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mimgs\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0msamples\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/opt/anaconda3/envs/deeplearning/lib/python3.7/site-packages/torchvision/datasets/folder.py\u001B[0m in \u001B[0;36m__init__\u001B[0;34m(self, root, loader, extensions, transform, target_transform, is_valid_file)\u001B[0m\n\u001B[1;32m    106\u001B[0m         super(DatasetFolder, self).__init__(root, transform=transform,\n\u001B[1;32m    107\u001B[0m                                             target_transform=target_transform)\n\u001B[0;32m--> 108\u001B[0;31m         \u001B[0mclasses\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mclass_to_idx\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_find_classes\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mroot\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    109\u001B[0m         \u001B[0msamples\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mmake_dataset\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mroot\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mclass_to_idx\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mextensions\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mis_valid_file\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    110\u001B[0m         \u001B[0;32mif\u001B[0m \u001B[0mlen\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0msamples\u001B[0m\u001B[0;34m)\u001B[0m \u001B[0;34m==\u001B[0m \u001B[0;36m0\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/opt/anaconda3/envs/deeplearning/lib/python3.7/site-packages/torchvision/datasets/folder.py\u001B[0m in \u001B[0;36m_find_classes\u001B[0;34m(self, dir)\u001B[0m\n\u001B[1;32m    135\u001B[0m             \u001B[0mNo\u001B[0m \u001B[0;32mclass\u001B[0m \u001B[0;32mis\u001B[0m \u001B[0ma\u001B[0m \u001B[0msubdirectory\u001B[0m \u001B[0mof\u001B[0m \u001B[0manother\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    136\u001B[0m         \"\"\"\n\u001B[0;32m--> 137\u001B[0;31m         \u001B[0mclasses\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0;34m[\u001B[0m\u001B[0md\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mname\u001B[0m \u001B[0;32mfor\u001B[0m \u001B[0md\u001B[0m \u001B[0;32min\u001B[0m \u001B[0mos\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mscandir\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mdir\u001B[0m\u001B[0;34m)\u001B[0m \u001B[0;32mif\u001B[0m \u001B[0md\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mis_dir\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    138\u001B[0m         \u001B[0mclasses\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0msort\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    139\u001B[0m         \u001B[0mclass_to_idx\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0;34m{\u001B[0m\u001B[0mcls_name\u001B[0m\u001B[0;34m:\u001B[0m \u001B[0mi\u001B[0m \u001B[0;32mfor\u001B[0m \u001B[0mi\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mcls_name\u001B[0m \u001B[0;32min\u001B[0m \u001B[0menumerate\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mclasses\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m}\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;31mFileNotFoundError\u001B[0m: [Errno 2] No such file or directory: 'D:\\\\School\\\\SE\\\\Group_Project\\\\data/train'"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function, division\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.optim import lr_scheduler\n",
    "from torch.autograd import Variable\n",
    "import numpy as np\n",
    "import torchvision\n",
    "from torchvision import datasets, models, transforms\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import os\n",
    "import copy\n",
    "\"\"\"This file allows you to create a ML model that uses transfer learning and\n",
    "    vgg16 to classify images \"\"\"\n",
    "def main():\n",
    "  pass\n",
    "\n",
    "if __name__ == '__main__':\n",
    "\n",
    "    #Check to see if CUDA is availble on the running systems.\n",
    "    use_gpu = torch.cuda.is_available()\n",
    "    if use_gpu:\n",
    "        print(\"Using CUDA\")\n",
    "\n",
    "    # Loading this dataset with pytorch is really easy using ImageFolder\n",
    "    # as the labels are specified by the folders names.\n",
    "    # This folder path will be custom for each member\n",
    "    data_dir = r'D:\\School\\SE\\Group_Project\\data'\n",
    "    TRAIN = 'train'\n",
    "    VAL = 'val'\n",
    "    TEST = 'test'\n",
    "\n",
    "    # VGG-16 Takes 224x224 images as input, so we resize all of them\n",
    "    #it also takes normalization as specified at pytorch.com\n",
    "    data_transforms = {\n",
    "        TRAIN: transforms.Compose([\n",
    "            # Data augmentation is a good practice for the train set\n",
    "            # Here, we randomly crop the image to 224x224 and\n",
    "            # randomly flip it horizontally (seems like best fit for graphs?)\n",
    "            transforms.RandomResizedCrop(224),\n",
    "            transforms.RandomHorizontalFlip(),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225))\n",
    "        ]),\n",
    "        VAL: transforms.Compose([\n",
    "            transforms.Resize(256),\n",
    "            transforms.CenterCrop(224),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225))\n",
    "        ]),\n",
    "        TEST: transforms.Compose([\n",
    "            transforms.Resize(256),\n",
    "            transforms.CenterCrop(224),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225))\n",
    "        ])\n",
    "    }\n",
    "\n",
    "    #creating our data set\n",
    "    image_datasets = {\n",
    "        x: datasets.ImageFolder(\n",
    "            os.path.join(data_dir, x),\n",
    "            transform=data_transforms[x]\n",
    "        )\n",
    "        for x in [TRAIN, VAL, TEST]\n",
    "    }\n",
    "\n",
    "    #low batch sizes allow for our computers to compute these predictions as they don't use much\n",
    "    #video memory\n",
    "    dataloaders = {\n",
    "        x: torch.utils.data.DataLoader(\n",
    "            image_datasets[x], batch_size=8,\n",
    "            shuffle=True, num_workers=4\n",
    "        )\n",
    "        for x in [TRAIN, VAL, TEST]\n",
    "    }\n",
    "\n",
    "    dataset_sizes = {x: len(image_datasets[x]) for x in [TRAIN, VAL, TEST]}\n",
    "\n",
    "    for x in [TRAIN, VAL, TEST]:\n",
    "        print(\"Loaded {} images under {}\".format(dataset_sizes[x], x))\n",
    "\n",
    "\n",
    "    print(\"Classes: \")\n",
    "    class_names = image_datasets[TRAIN].classes\n",
    "    print(image_datasets[TRAIN].classes)\n",
    "\n",
    "\n",
    "    #simple function to show images\n",
    "    def imshow(inp, title=None):\n",
    "        inp = inp.numpy().transpose((1, 2, 0))\n",
    "        plt.axis('off')\n",
    "        plt.imshow(inp)\n",
    "        if title is not None:\n",
    "            plt.title(title)\n",
    "        plt.pause(0.001)\n",
    "    \n",
    "    \n",
    "    #function used in tandem with imshow to\n",
    "    def show_databatch(inputs, classes):\n",
    "        out = torchvision.utils.make_grid(inputs)\n",
    "        imshow(out, title=[class_names[x] for x in classes])\n",
    "    \n",
    "    \n",
    "    inputs, classes = next(iter(dataloaders[TRAIN]))\n",
    "    show_databatch(inputs, classes)\n",
    "    \n",
    "    #allows the integration of matplot lib to see some data\n",
    "    def visualize_model(vgg, num_images=6):\n",
    "        was_training = vgg.training\n",
    "    \n",
    "        # Set model for evaluation\n",
    "        vgg.train(False)\n",
    "        vgg.eval()\n",
    "    \n",
    "        images_so_far = 0\n",
    "    \n",
    "        for i, data in enumerate(dataloaders[TEST]):\n",
    "            inputs, labels = data\n",
    "            size = inputs.size()[0]\n",
    "    \n",
    "            if use_gpu:\n",
    "                inputs, labels = Variable(inputs.cuda(), volatile=True), Variable(labels.cuda(), volatile=True)\n",
    "            else:\n",
    "                inputs, labels = Variable(inputs, volatile=True), Variable(labels, volatile=True)\n",
    "    \n",
    "            outputs = vgg(inputs)\n",
    "    \n",
    "            _, preds = torch.max(outputs.data, 1)\n",
    "            predicted_labels = [preds[j] for j in range(inputs.size()[0])]\n",
    "    \n",
    "            print(\"Ground truth:\")\n",
    "            show_databatch(inputs.data.cpu(), labels.data.cpu())\n",
    "            print(\"Prediction:\")\n",
    "            show_databatch(inputs.data.cpu(), predicted_labels)\n",
    "    \n",
    "            del inputs, labels, outputs, preds, predicted_labels\n",
    "            torch.cuda.empty_cache()\n",
    "    \n",
    "            images_so_far += size\n",
    "            if images_so_far >= num_images:\n",
    "                break\n",
    "    \n",
    "        vgg.train(mode=was_training)  # Revert model back to original training state\n",
    "    \n",
    "    #pretraining evaluation\n",
    "    def eval_model(vgg, criterion):\n",
    "        since = time.time()\n",
    "        avg_loss = 0\n",
    "        avg_acc = 0\n",
    "        loss_test = 0\n",
    "        acc_test = 0\n",
    "    \n",
    "        test_batches = len(dataloaders[TEST])\n",
    "        print(\"Evaluating model\")\n",
    "        print('-' * 10)\n",
    "    \n",
    "        for i, data in enumerate(dataloaders[TEST]):\n",
    "            if i % 100 == 0:\n",
    "                print(\"\\rTest batch {}/{}\".format(i, test_batches), end='', flush=True)\n",
    "    \n",
    "            vgg.train(False)\n",
    "            vgg.eval()\n",
    "            inputs, labels = data\n",
    "    \n",
    "            if use_gpu:\n",
    "                inputs, labels = Variable(inputs.cuda(), volatile=True), Variable(labels.cuda(), volatile=True)\n",
    "            else:\n",
    "                inputs, labels = Variable(inputs, volatile=True), Variable(labels, volatile=True)\n",
    "    \n",
    "            outputs = vgg(inputs)\n",
    "    \n",
    "            _, preds = torch.max(outputs.data, 1)\n",
    "            loss = criterion(outputs, labels)\n",
    "    \n",
    "            loss_test += loss.data\n",
    "            acc_test += torch.sum(preds == labels.data)\n",
    "    \n",
    "            del inputs, labels, outputs, preds\n",
    "            torch.cuda.empty_cache()\n",
    "    \n",
    "        avg_loss = loss_test / dataset_sizes[TEST]\n",
    "        avg_acc = acc_test / dataset_sizes[TEST]\n",
    "    \n",
    "        elapsed_time = time.time() - since\n",
    "        print()\n",
    "        print(\"Evaluation completed in {:.0f}m {:.0f}s\".format(elapsed_time // 60, elapsed_time % 60))\n",
    "        print(\"Avg loss (test): {:.4f}\".format(avg_loss))\n",
    "        print(\"Avg acc (test): {:.4f}\".format(avg_acc))\n",
    "        print('-' * 10)\n",
    "    \n",
    "    \n",
    "    #Load the pretrained model from pytorch\n",
    "    vgg16 = models.vgg16_bn()\n",
    "    \n",
    "    # Freeze training for all layers\n",
    "    for param in vgg16.features.parameters():\n",
    "        param.require_grad = False\n",
    "    \n",
    "    # Newly created modules have require_grad=True by default\n",
    "    num_features = vgg16.classifier[6].in_features\n",
    "    features = list(vgg16.classifier.children())[:-1]  # Remove last layer\n",
    "    features.extend([nn.Linear(num_features, len(class_names))])  # Add our layer with 3 outputs\n",
    "    vgg16.classifier = nn.Sequential(*features)  # Replace the model classifier\n",
    "\n",
    "\n",
    "    \n",
    "    # If you want to train the model for more than 2 epochs,\n",
    "    # set this to True after the first run\n",
    "    resume_training = False\n",
    "    \n",
    "    if resume_training:\n",
    "        print(\"Loading pretrained model..\")\n",
    "        vgg16.load_state_dict(torch.load('/Users/matthew/PycharmProjects/CSCI338_Project/VGG16_graphs.pt'))\n",
    "\n",
    "    \n",
    "    if use_gpu:\n",
    "        vgg16.cuda()  # .cuda() will move everything to the GPU side\n",
    "    \n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "    #optimization (possibly could use atom)\n",
    "    optimizer_ft = optim.SGD(vgg16.parameters(), lr=0.001, momentum=0.9)\n",
    "    exp_lr_scheduler = lr_scheduler.StepLR(optimizer_ft, step_size=7, gamma=0.1)\n",
    "    \n",
    "    \n",
    "    \n",
    "    print(\"Test before training\")\n",
    "    eval_model(vgg16, criterion)\n",
    "    \n",
    "    \n",
    "    visualize_model(vgg16) #test before training\n",
    "\n",
    "    #(training the actual model, as followed from pytorch)\n",
    "    def train_model(vgg, criterion, optimizer, scheduler, num_epochs=10):\n",
    "        since = time.time()\n",
    "        best_model_wts = copy.deepcopy(vgg.state_dict())\n",
    "        best_acc = 0.0\n",
    "\n",
    "        avg_loss = 0\n",
    "        avg_acc = 0\n",
    "        avg_loss_val = 0\n",
    "        avg_acc_val = 0\n",
    "\n",
    "        train_batches = len(dataloaders[TRAIN])\n",
    "        val_batches = len(dataloaders[VAL])\n",
    "\n",
    "        for epoch in range(num_epochs):\n",
    "            print(\"Epoch {}/{}\".format(epoch, num_epochs))\n",
    "            print('-' * 10)\n",
    "\n",
    "            loss_train = 0\n",
    "            loss_val = 0\n",
    "            acc_train = 0\n",
    "            acc_val = 0\n",
    "\n",
    "            vgg.train(True)\n",
    "\n",
    "            for i, data in enumerate(dataloaders[TRAIN]):\n",
    "                if i % 100 == 0:\n",
    "                    print(\"\\rTraining batch {}/{}\".format(i, train_batches / 2), end='', flush=True)\n",
    "\n",
    "                # Use half training dataset\n",
    "                if i >= train_batches / 2:\n",
    "                    break\n",
    "\n",
    "                inputs, labels = data\n",
    "\n",
    "                if use_gpu:\n",
    "                    inputs, labels = Variable(inputs.cuda()), Variable(labels.cuda())\n",
    "                else:\n",
    "                    inputs, labels = Variable(inputs), Variable(labels)\n",
    "\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                outputs = vgg(inputs)\n",
    "\n",
    "                _, preds = torch.max(outputs.data, 1)\n",
    "                loss = criterion(outputs, labels)\n",
    "\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "\n",
    "                loss_train += loss.data\n",
    "                acc_train += torch.sum(preds == labels.data)\n",
    "\n",
    "                del inputs, labels, outputs, preds\n",
    "                torch.cuda.empty_cache()\n",
    "\n",
    "            print()\n",
    "            # * 2 as we only used half of the dataset\n",
    "            avg_loss = loss_train * 2 / dataset_sizes[TRAIN]\n",
    "            avg_acc = acc_train * 2 / dataset_sizes[TRAIN]\n",
    "\n",
    "            vgg.train(False)\n",
    "            vgg.eval()\n",
    "\n",
    "            for i, data in enumerate(dataloaders[VAL]):\n",
    "                if i % 100 == 0:\n",
    "                    print(\"\\rValidation batch {}/{}\".format(i, val_batches), end='', flush=True)\n",
    "\n",
    "                inputs, labels = data\n",
    "\n",
    "                if use_gpu:\n",
    "                    inputs, labels = Variable(inputs.cuda(), volatile=True), Variable(labels.cuda(), volatile=True)\n",
    "                else:\n",
    "                    inputs, labels = Variable(inputs, volatile=True), Variable(labels, volatile=True)\n",
    "\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                outputs = vgg(inputs)\n",
    "\n",
    "                _, preds = torch.max(outputs.data, 1)\n",
    "                loss = criterion(outputs, labels)\n",
    "\n",
    "                loss_val += loss.data[0]\n",
    "                acc_val += torch.sum(preds == labels.data)\n",
    "\n",
    "                del inputs, labels, outputs, preds\n",
    "                torch.cuda.empty_cache()\n",
    "\n",
    "            avg_loss_val = loss_val / dataset_sizes[VAL]\n",
    "            avg_acc_val = acc_val / dataset_sizes[VAL]\n",
    "\n",
    "            print()\n",
    "            print(\"Epoch {} result: \".format(epoch))\n",
    "            print(\"Avg loss (train): {:.4f}\".format(avg_loss))\n",
    "            print(\"Avg acc (train): {:.4f}\".format(avg_acc))\n",
    "            print(\"Avg loss (val): {:.4f}\".format(avg_loss_val))\n",
    "            print(\"Avg acc (val): {:.4f}\".format(avg_acc_val))\n",
    "            print('-' * 10)\n",
    "            print()\n",
    "\n",
    "            if avg_acc_val > best_acc:\n",
    "                best_acc = avg_acc_val\n",
    "                best_model_wts = copy.deepcopy(vgg.state_dict())\n",
    "\n",
    "        elapsed_time = time.time() - since\n",
    "        print()\n",
    "        print(\"Training completed in {:.0f}m {:.0f}s\".format(elapsed_time // 60, elapsed_time % 60))\n",
    "        print(\"Best acc: {:.4f}\".format(best_acc))\n",
    "\n",
    "        vgg.load_state_dict(best_model_wts)\n",
    "        return vgg\n",
    "    \n",
    "    #train model\n",
    "    vgg16 = train_model(vgg16, criterion, optimizer_ft, exp_lr_scheduler, num_epochs=2)\n",
    "\n",
    "    #take this model and use the data in the remainder of the picture in the testing folder\n",
    "    torch.save(vgg16.state_dict(), 'VGG16_graphs.pt')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13d61f14",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "535f0c7f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}