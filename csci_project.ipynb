{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a1bbe8ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using CUDA\n",
      "Loaded 363069 images under train\n",
      "Loaded 11932 images under val\n",
      "Loaded 11965 images under test\n",
      "Classes: \n",
      "['bar', 'line', 'pie']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000\n",
      "VGG(\n",
      "  (features): Sequential(\n",
      "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): ReLU(inplace=True)\n",
      "    (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (5): ReLU(inplace=True)\n",
      "    (6): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (7): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (8): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (9): ReLU(inplace=True)\n",
      "    (10): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (11): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (12): ReLU(inplace=True)\n",
      "    (13): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (14): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (15): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (16): ReLU(inplace=True)\n",
      "    (17): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (18): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (19): ReLU(inplace=True)\n",
      "    (20): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (21): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (22): ReLU(inplace=True)\n",
      "    (23): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (24): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (25): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (26): ReLU(inplace=True)\n",
      "    (27): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (28): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (29): ReLU(inplace=True)\n",
      "    (30): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (31): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (32): ReLU(inplace=True)\n",
      "    (33): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (34): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (35): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (36): ReLU(inplace=True)\n",
      "    (37): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (38): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (39): ReLU(inplace=True)\n",
      "    (40): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (41): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (42): ReLU(inplace=True)\n",
      "    (43): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (avgpool): AdaptiveAvgPool2d(output_size=(7, 7))\n",
      "  (classifier): Sequential(\n",
      "    (0): Linear(in_features=25088, out_features=4096, bias=True)\n",
      "    (1): ReLU(inplace=True)\n",
      "    (2): Dropout(p=0.5, inplace=False)\n",
      "    (3): Linear(in_features=4096, out_features=4096, bias=True)\n",
      "    (4): ReLU(inplace=True)\n",
      "    (5): Dropout(p=0.5, inplace=False)\n",
      "    (6): Linear(in_features=4096, out_features=3, bias=True)\n",
      "  )\n",
      ")\n",
      "Test before training\n",
      "Evaluating model\n",
      "----------\n",
      "Test batch 0/1496"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda\\envs\\deep_learning\\lib\\site-packages\\ipykernel_launcher.py:182: UserWarning: volatile was removed and now has no effect. Use `with torch.no_grad():` instead.\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "CUDA out of memory. Tried to allocate 50.00 MiB (GPU 0; 6.00 GiB total capacity; 4.03 GiB already allocated; 35.00 MiB free; 4.05 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mRuntimeError\u001B[0m                              Traceback (most recent call last)",
      "\u001B[1;32m~\\AppData\\Local\\Temp\\ipykernel_7968\\482346681.py\u001B[0m in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[0;32m    243\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    244\u001B[0m     \u001B[0mprint\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;34m\"Test before training\"\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 245\u001B[1;33m     \u001B[0meval_model\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mvgg16\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mcriterion\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    246\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    247\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\AppData\\Local\\Temp\\ipykernel_7968\\482346681.py\u001B[0m in \u001B[0;36meval_model\u001B[1;34m(vgg, criterion)\u001B[0m\n\u001B[0;32m    184\u001B[0m                 \u001B[0minputs\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mlabels\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mVariable\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0minputs\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mvolatile\u001B[0m\u001B[1;33m=\u001B[0m\u001B[1;32mTrue\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mVariable\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mlabels\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mvolatile\u001B[0m\u001B[1;33m=\u001B[0m\u001B[1;32mTrue\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    185\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 186\u001B[1;33m             \u001B[0moutputs\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mvgg\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0minputs\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    187\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    188\u001B[0m             \u001B[0m_\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mpreds\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mtorch\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mmax\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0moutputs\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mdata\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;36m1\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mD:\\Anaconda\\envs\\deep_learning\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001B[0m in \u001B[0;36m_call_impl\u001B[1;34m(self, *input, **kwargs)\u001B[0m\n\u001B[0;32m   1108\u001B[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001B[0;32m   1109\u001B[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001B[1;32m-> 1110\u001B[1;33m             \u001B[1;32mreturn\u001B[0m \u001B[0mforward_call\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m*\u001B[0m\u001B[0minput\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m   1111\u001B[0m         \u001B[1;31m# Do not call functions when jit is used\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   1112\u001B[0m         \u001B[0mfull_backward_hooks\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mnon_full_backward_hooks\u001B[0m \u001B[1;33m=\u001B[0m \u001B[1;33m[\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m[\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mD:\\Anaconda\\envs\\deep_learning\\lib\\site-packages\\torchvision\\models\\vgg.py\u001B[0m in \u001B[0;36mforward\u001B[1;34m(self, x)\u001B[0m\n\u001B[0;32m     64\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     65\u001B[0m     \u001B[1;32mdef\u001B[0m \u001B[0mforward\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mx\u001B[0m\u001B[1;33m:\u001B[0m \u001B[0mtorch\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mTensor\u001B[0m\u001B[1;33m)\u001B[0m \u001B[1;33m->\u001B[0m \u001B[0mtorch\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mTensor\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m---> 66\u001B[1;33m         \u001B[0mx\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mfeatures\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mx\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m     67\u001B[0m         \u001B[0mx\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mavgpool\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mx\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     68\u001B[0m         \u001B[0mx\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mtorch\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mflatten\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mx\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;36m1\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mD:\\Anaconda\\envs\\deep_learning\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001B[0m in \u001B[0;36m_call_impl\u001B[1;34m(self, *input, **kwargs)\u001B[0m\n\u001B[0;32m   1108\u001B[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001B[0;32m   1109\u001B[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001B[1;32m-> 1110\u001B[1;33m             \u001B[1;32mreturn\u001B[0m \u001B[0mforward_call\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m*\u001B[0m\u001B[0minput\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m   1111\u001B[0m         \u001B[1;31m# Do not call functions when jit is used\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   1112\u001B[0m         \u001B[0mfull_backward_hooks\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mnon_full_backward_hooks\u001B[0m \u001B[1;33m=\u001B[0m \u001B[1;33m[\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m[\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mD:\\Anaconda\\envs\\deep_learning\\lib\\site-packages\\torch\\nn\\modules\\container.py\u001B[0m in \u001B[0;36mforward\u001B[1;34m(self, input)\u001B[0m\n\u001B[0;32m    139\u001B[0m     \u001B[1;32mdef\u001B[0m \u001B[0mforward\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0minput\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    140\u001B[0m         \u001B[1;32mfor\u001B[0m \u001B[0mmodule\u001B[0m \u001B[1;32min\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 141\u001B[1;33m             \u001B[0minput\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mmodule\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0minput\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    142\u001B[0m         \u001B[1;32mreturn\u001B[0m \u001B[0minput\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    143\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mD:\\Anaconda\\envs\\deep_learning\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001B[0m in \u001B[0;36m_call_impl\u001B[1;34m(self, *input, **kwargs)\u001B[0m\n\u001B[0;32m   1108\u001B[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001B[0;32m   1109\u001B[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001B[1;32m-> 1110\u001B[1;33m             \u001B[1;32mreturn\u001B[0m \u001B[0mforward_call\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m*\u001B[0m\u001B[0minput\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m   1111\u001B[0m         \u001B[1;31m# Do not call functions when jit is used\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   1112\u001B[0m         \u001B[0mfull_backward_hooks\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mnon_full_backward_hooks\u001B[0m \u001B[1;33m=\u001B[0m \u001B[1;33m[\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m[\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mD:\\Anaconda\\envs\\deep_learning\\lib\\site-packages\\torch\\nn\\modules\\conv.py\u001B[0m in \u001B[0;36mforward\u001B[1;34m(self, input)\u001B[0m\n\u001B[0;32m    445\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    446\u001B[0m     \u001B[1;32mdef\u001B[0m \u001B[0mforward\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0minput\u001B[0m\u001B[1;33m:\u001B[0m \u001B[0mTensor\u001B[0m\u001B[1;33m)\u001B[0m \u001B[1;33m->\u001B[0m \u001B[0mTensor\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 447\u001B[1;33m         \u001B[1;32mreturn\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_conv_forward\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0minput\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mweight\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mbias\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    448\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    449\u001B[0m \u001B[1;32mclass\u001B[0m \u001B[0mConv3d\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0m_ConvNd\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mD:\\Anaconda\\envs\\deep_learning\\lib\\site-packages\\torch\\nn\\modules\\conv.py\u001B[0m in \u001B[0;36m_conv_forward\u001B[1;34m(self, input, weight, bias)\u001B[0m\n\u001B[0;32m    442\u001B[0m                             _pair(0), self.dilation, self.groups)\n\u001B[0;32m    443\u001B[0m         return F.conv2d(input, weight, bias, self.stride,\n\u001B[1;32m--> 444\u001B[1;33m                         self.padding, self.dilation, self.groups)\n\u001B[0m\u001B[0;32m    445\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    446\u001B[0m     \u001B[1;32mdef\u001B[0m \u001B[0mforward\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0minput\u001B[0m\u001B[1;33m:\u001B[0m \u001B[0mTensor\u001B[0m\u001B[1;33m)\u001B[0m \u001B[1;33m->\u001B[0m \u001B[0mTensor\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;31mRuntimeError\u001B[0m: CUDA out of memory. Tried to allocate 50.00 MiB (GPU 0; 6.00 GiB total capacity; 4.03 GiB already allocated; 35.00 MiB free; 4.05 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function, division\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.optim import lr_scheduler\n",
    "from torch.autograd import Variable\n",
    "import numpy as np\n",
    "import torchvision\n",
    "from torchvision import datasets, models, transforms\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import os\n",
    "import copy\n",
    "\n",
    "def main():\n",
    "  pass\n",
    "\n",
    "if __name__ == '__main__':\n",
    "\n",
    "    #Check to see if CUDA is availble on the running systems.\n",
    "    use_gpu = torch.cuda.is_available()\n",
    "    if use_gpu:\n",
    "        print(\"Using CUDA\")\n",
    "\n",
    "    # Loading this dataset with pytorch is really easy using ImageFolder\n",
    "    # as the labels are specified by the folders names.\n",
    "    # This folder path will be custom for each member\n",
    "    data_dir = r'D:\\School\\SE\\Group_Project\\data'\n",
    "    TRAIN = 'train'\n",
    "    VAL = 'val'\n",
    "    TEST = 'test'\n",
    "\n",
    "    # VGG-16 Takes 224x224 images as input, so we resize all of them\n",
    "    #it also takes normalization as specified at pytorch.com\n",
    "    data_transforms = {\n",
    "        TRAIN: transforms.Compose([\n",
    "            # Data augmentation is a good practice for the train set\n",
    "            # Here, we randomly crop the image to 224x224 and\n",
    "            # randomly flip it horizontally (seems like best fit for graphs?)\n",
    "            transforms.RandomResizedCrop(224),\n",
    "            transforms.RandomHorizontalFlip(),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225))\n",
    "        ]),\n",
    "        VAL: transforms.Compose([\n",
    "            transforms.Resize(256),\n",
    "            transforms.CenterCrop(224),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225))\n",
    "        ]),\n",
    "        TEST: transforms.Compose([\n",
    "            transforms.Resize(256),\n",
    "            transforms.CenterCrop(224),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225))\n",
    "        ])\n",
    "    }\n",
    "\n",
    "    #creating our data set\n",
    "    image_datasets = {\n",
    "        x: datasets.ImageFolder(\n",
    "            os.path.join(data_dir, x),\n",
    "            transform=data_transforms[x]\n",
    "        )\n",
    "        for x in [TRAIN, VAL, TEST]\n",
    "    }\n",
    "\n",
    "    #low batch sizes allow for our computers to compute these predicitions as they don't use much\n",
    "    #video memory\n",
    "    dataloaders = {\n",
    "        x: torch.utils.data.DataLoader(\n",
    "            image_datasets[x], batch_size=8,\n",
    "            shuffle=True, num_workers=4\n",
    "        )\n",
    "        for x in [TRAIN, VAL, TEST]\n",
    "    }\n",
    "\n",
    "    dataset_sizes = {x: len(image_datasets[x]) for x in [TRAIN, VAL, TEST]}\n",
    "\n",
    "    for x in [TRAIN, VAL, TEST]:\n",
    "        print(\"Loaded {} images under {}\".format(dataset_sizes[x], x))\n",
    "\n",
    "\n",
    "    print(\"Classes: \")\n",
    "    class_names = image_datasets[TRAIN].classes\n",
    "    print(image_datasets[TRAIN].classes)\n",
    "\n",
    "\n",
    "#     def imshow(inp, title=None):\n",
    "#         \"\"\"Imshow for Tensor.\"\"\"\n",
    "#         inp = inp.numpy().transpose((1, 2, 0))\n",
    "#         mean = np.array([0.485, 0.456, 0.406])\n",
    "#         std = np.array([0.229, 0.224, 0.225])\n",
    "#         inp = std * inp + mean\n",
    "#         inp = np.clip(inp, 0, 1)\n",
    "#         plt.imshow(inp)\n",
    "#         if title is not None:\n",
    "#             plt.title(title)\n",
    "#         plt.pause(0.001)  # pause a bit so that plots are updated\n",
    "\n",
    "#     #Get a batch of training data\n",
    "#     inputs, classes = next(iter(dataloaders[TRAIN]))\n",
    "#     #Make a grid from batch\n",
    "#     out = torchvision.utils.make_grid(inputs)\n",
    "#     imshow(out, title=[class_names[x] for x in classes])\n",
    "\n",
    "    \n",
    "    def imshow(inp, title=None):\n",
    "        inp = inp.numpy().transpose((1, 2, 0))\n",
    "        # plt.figure(figsize=(10, 10))\n",
    "        plt.axis('off')\n",
    "        plt.imshow(inp)\n",
    "        if title is not None:\n",
    "            plt.title(title)\n",
    "        plt.pause(0.001)\n",
    "    \n",
    "    \n",
    "    \n",
    "    def show_databatch(inputs, classes):\n",
    "        out = torchvision.utils.make_grid(inputs)\n",
    "        imshow(out, title=[class_names[x] for x in classes])\n",
    "    \n",
    "    \n",
    "    inputs, classes = next(iter(dataloaders[TRAIN]))\n",
    "    show_databatch(inputs, classes)\n",
    "    \n",
    "    #allows the itegration of matplot lib to see some data\n",
    "    def visualize_model(vgg, num_images=6):\n",
    "        was_training = vgg.training\n",
    "    \n",
    "        # Set model for evaluation\n",
    "        vgg.train(False)\n",
    "        vgg.eval()\n",
    "    \n",
    "        images_so_far = 0\n",
    "    \n",
    "        for i, data in enumerate(dataloaders[TEST]):\n",
    "            inputs, labels = data\n",
    "            size = inputs.size()[0]\n",
    "    \n",
    "            if use_gpu:\n",
    "                inputs, labels = Variable(inputs.cuda(), volatile=True), Variable(labels.cuda(), volatile=True)\n",
    "            else:\n",
    "                inputs, labels = Variable(inputs, volatile=True), Variable(labels, volatile=True)\n",
    "    \n",
    "            outputs = vgg(inputs)\n",
    "    \n",
    "            _, preds = torch.max(outputs.data, 1)\n",
    "            predicted_labels = [preds[j] for j in range(inputs.size()[0])]\n",
    "    \n",
    "            print(\"Ground truth:\")\n",
    "            show_databatch(inputs.data.cpu(), labels.data.cpu())\n",
    "            print(\"Prediction:\")\n",
    "            show_databatch(inputs.data.cpu(), predicted_labels)\n",
    "    \n",
    "            del inputs, labels, outputs, preds, predicted_labels\n",
    "            torch.cuda.empty_cache()\n",
    "    \n",
    "            images_so_far += size\n",
    "            if images_so_far >= num_images:\n",
    "                break\n",
    "    \n",
    "        vgg.train(mode=was_training)  # Revert model back to original training state\n",
    "    \n",
    "    #pretraining evaluation\n",
    "    def eval_model(vgg, criterion):\n",
    "        since = time.time()\n",
    "        avg_loss = 0\n",
    "        avg_acc = 0\n",
    "        loss_test = 0\n",
    "        acc_test = 0\n",
    "    \n",
    "        test_batches = len(dataloaders[TEST])\n",
    "        print(\"Evaluating model\")\n",
    "        print('-' * 10)\n",
    "    \n",
    "        for i, data in enumerate(dataloaders[TEST]):\n",
    "            if i % 100 == 0:\n",
    "                print(\"\\rTest batch {}/{}\".format(i, test_batches), end='', flush=True)\n",
    "    \n",
    "            vgg.train(False)\n",
    "            vgg.eval()\n",
    "            inputs, labels = data\n",
    "    \n",
    "            if use_gpu:\n",
    "                inputs, labels = Variable(inputs.cuda(), volatile=True), Variable(labels.cuda(), volatile=True)\n",
    "            else:\n",
    "                inputs, labels = Variable(inputs, volatile=True), Variable(labels, volatile=True)\n",
    "    \n",
    "            outputs = vgg(inputs)\n",
    "    \n",
    "            _, preds = torch.max(outputs.data, 1)\n",
    "            loss = criterion(outputs, labels)\n",
    "    \n",
    "            loss_test += loss.data\n",
    "            acc_test += torch.sum(preds == labels.data)\n",
    "    \n",
    "            del inputs, labels, outputs, preds\n",
    "            torch.cuda.empty_cache()\n",
    "    \n",
    "        avg_loss = loss_test / dataset_sizes[TEST]\n",
    "        avg_acc = acc_test / dataset_sizes[TEST]\n",
    "    \n",
    "        elapsed_time = time.time() - since\n",
    "        print()\n",
    "        print(\"Evaluation completed in {:.0f}m {:.0f}s\".format(elapsed_time // 60, elapsed_time % 60))\n",
    "        print(\"Avg loss (test): {:.4f}\".format(avg_loss))\n",
    "        print(\"Avg acc (test): {:.4f}\".format(avg_acc))\n",
    "        print('-' * 10)\n",
    "    \n",
    "    \n",
    "    # # Load the pretrained model from pytorch\n",
    "    vgg16 = models.vgg16_bn()\n",
    "\n",
    "    # #vgg16.load_state_dict(torch.load(\"../input/vgg16bn/vgg16_bn.pth\"))\n",
    "    print(vgg16.classifier[6].out_features)  # 1000\n",
    "    \n",
    "    # Freeze training for all layers\n",
    "    for param in vgg16.features.parameters():\n",
    "        param.require_grad = False\n",
    "    \n",
    "    # Newly created modules have require_grad=True by default\n",
    "    num_features = vgg16.classifier[6].in_features\n",
    "    features = list(vgg16.classifier.children())[:-1]  # Remove last layer\n",
    "    features.extend([nn.Linear(num_features, len(class_names))])  # Add our layer with 4 outputs\n",
    "    vgg16.classifier = nn.Sequential(*features)  # Replace the model classifier\n",
    "    print(vgg16)\n",
    "    \n",
    "    \n",
    "    \n",
    "    # If you want to train the model for more than 2 epochs,\n",
    "    # set this to True after the first run\n",
    "    resume_training = False\n",
    "    \n",
    "    if resume_training:\n",
    "        print(\"Loading pretrained model..\")\n",
    "        vgg16.load_state_dict(torch.load('../input/vgg16-transfer-learning-pytorch/VGG16_v2-OCT_Retina.pt'))\n",
    "        print(\"Loaded!\")\n",
    "    \n",
    "    if use_gpu:\n",
    "        vgg16.cuda()  # .cuda() will move everything to the GPU side\n",
    "    \n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "    #optimization (possibly could use atom)\n",
    "    optimizer_ft = optim.SGD(vgg16.parameters(), lr=0.001, momentum=0.9)\n",
    "    exp_lr_scheduler = lr_scheduler.StepLR(optimizer_ft, step_size=7, gamma=0.1)\n",
    "    \n",
    "    \n",
    "    \n",
    "    print(\"Test before training\")\n",
    "    eval_model(vgg16, criterion)\n",
    "    \n",
    "    \n",
    "    visualize_model(vgg16) #test before training\n",
    "\n",
    "    #(training the actual model)\n",
    "    def train_model(vgg, criterion, optimizer, scheduler, num_epochs=10):\n",
    "        since = time.time()\n",
    "        best_model_wts = copy.deepcopy(vgg.state_dict())\n",
    "        best_acc = 0.0\n",
    "\n",
    "        avg_loss = 0\n",
    "        avg_acc = 0\n",
    "        avg_loss_val = 0\n",
    "        avg_acc_val = 0\n",
    "\n",
    "        train_batches = len(dataloaders[TRAIN])\n",
    "        val_batches = len(dataloaders[VAL])\n",
    "\n",
    "        for epoch in range(num_epochs):\n",
    "            print(\"Epoch {}/{}\".format(epoch, num_epochs))\n",
    "            print('-' * 10)\n",
    "\n",
    "            loss_train = 0\n",
    "            loss_val = 0\n",
    "            acc_train = 0\n",
    "            acc_val = 0\n",
    "\n",
    "            vgg.train(True)\n",
    "\n",
    "            for i, data in enumerate(dataloaders[TRAIN]):\n",
    "                if i % 100 == 0:\n",
    "                    print(\"\\rTraining batch {}/{}\".format(i, train_batches / 2), end='', flush=True)\n",
    "\n",
    "                # Use half training dataset\n",
    "                if i >= train_batches / 2:\n",
    "                    break\n",
    "\n",
    "                inputs, labels = data\n",
    "\n",
    "                if use_gpu:\n",
    "                    inputs, labels = Variable(inputs.cuda()), Variable(labels.cuda())\n",
    "                else:\n",
    "                    inputs, labels = Variable(inputs), Variable(labels)\n",
    "\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                outputs = vgg(inputs)\n",
    "\n",
    "                _, preds = torch.max(outputs.data, 1)\n",
    "                loss = criterion(outputs, labels)\n",
    "\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "\n",
    "                loss_train += loss.data\n",
    "                acc_train += torch.sum(preds == labels.data)\n",
    "\n",
    "                del inputs, labels, outputs, preds\n",
    "                torch.cuda.empty_cache()\n",
    "\n",
    "            print()\n",
    "            # * 2 as we only used half of the dataset\n",
    "            avg_loss = loss_train * 2 / dataset_sizes[TRAIN]\n",
    "            avg_acc = acc_train * 2 / dataset_sizes[TRAIN]\n",
    "\n",
    "            vgg.train(False)\n",
    "            vgg.eval()\n",
    "\n",
    "            for i, data in enumerate(dataloaders[VAL]):\n",
    "                if i % 100 == 0:\n",
    "                    print(\"\\rValidation batch {}/{}\".format(i, val_batches), end='', flush=True)\n",
    "\n",
    "                inputs, labels = data\n",
    "\n",
    "                if use_gpu:\n",
    "                    inputs, labels = Variable(inputs.cuda(), volatile=True), Variable(labels.cuda(), volatile=True)\n",
    "                else:\n",
    "                    inputs, labels = Variable(inputs, volatile=True), Variable(labels, volatile=True)\n",
    "\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                outputs = vgg(inputs)\n",
    "\n",
    "                _, preds = torch.max(outputs.data, 1)\n",
    "                loss = criterion(outputs, labels)\n",
    "\n",
    "                loss_val += loss.data[0]\n",
    "                acc_val += torch.sum(preds == labels.data)\n",
    "\n",
    "                del inputs, labels, outputs, preds\n",
    "                torch.cuda.empty_cache()\n",
    "\n",
    "            avg_loss_val = loss_val / dataset_sizes[VAL]\n",
    "            avg_acc_val = acc_val / dataset_sizes[VAL]\n",
    "\n",
    "            print()\n",
    "            print(\"Epoch {} result: \".format(epoch))\n",
    "            print(\"Avg loss (train): {:.4f}\".format(avg_loss))\n",
    "            print(\"Avg acc (train): {:.4f}\".format(avg_acc))\n",
    "            print(\"Avg loss (val): {:.4f}\".format(avg_loss_val))\n",
    "            print(\"Avg acc (val): {:.4f}\".format(avg_acc_val))\n",
    "            print('-' * 10)\n",
    "            print()\n",
    "\n",
    "            if avg_acc_val > best_acc:\n",
    "                best_acc = avg_acc_val\n",
    "                best_model_wts = copy.deepcopy(vgg.state_dict())\n",
    "\n",
    "        elapsed_time = time.time() - since\n",
    "        print()\n",
    "        print(\"Training completed in {:.0f}m {:.0f}s\".format(elapsed_time // 60, elapsed_time % 60))\n",
    "        print(\"Best acc: {:.4f}\".format(best_acc))\n",
    "\n",
    "        vgg.load_state_dict(best_model_wts)\n",
    "        return vgg\n",
    "    \n",
    "    vgg16 = train_model(vgg16, criterion, optimizer_ft, exp_lr_scheduler, num_epochs=2)\n",
    "\n",
    "    #take this model and use the data in the remainder of the picture in the testing folder\n",
    "    torch.save(vgg16.state_dict(), 'VGG16_graphs.pt')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13d61f14",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "535f0c7f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}